import os
import glob
import pickle
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from tqdm import tqdm

# â€”â€”â€” ConfiguraÃ§Ãµes â€”â€”â€”
pasta_modelo    = "modelo_final"
pasta_amostras  = "teste"
pasta_resultados = "resultados_teste"
os.makedirs(pasta_resultados, exist_ok=True)

# mesmo downsampling usado no treinamento
sample_step = 10  

# â€”â€”â€” Carregar modelo e PCA â€”â€”â€”
print(f"\nğŸ“¦ Carregando modelo: {pasta_modelo}/modelo_final.keras")
model = load_model(os.path.join(pasta_modelo, "modelo_final.keras"))

print(f"ğŸ“¦ Carregando PCA: {pasta_modelo}/pca.pkl")
with open(os.path.join(pasta_modelo, "pca.pkl"), "rb") as f:
    pca = pickle.load(f)

# â€”â€”â€” Encontrar amostras de teste â€”â€”â€”
arquivos_csv = sorted(glob.glob(os.path.join(pasta_amostras, "*.csv")))
print(f"\nğŸ” Lendo {len(arquivos_csv)} amostras em '{pasta_amostras}'...\n")

resultados = []

# â€”â€”â€” Loop de inferÃªncia â€”â€”â€”
for path in tqdm(arquivos_csv, desc="Testando amostras"):
    try:
        # 1) Leitura com pandas (igual ao treinamento)
        df = pd.read_csv(path)
        df = df.drop(df.columns[0], axis=1)                          # remove coluna de tempo
        df = df.loc[:, ~df.columns.str.startswith("Unnamed")]        # descarta colunas vazias
        df = df.fillna(0.0)
        # 2) Downsampling temporal (se usado no treinamento)
        df = df.iloc[::sample_step, :].reset_index(drop=True)

        # 3) Flatten e reshape
        arr = df.to_numpy(dtype="float32").flatten().reshape(1, -1)

        # 4) Verificar compatibilidade de shape
        if arr.shape[1] != pca.n_features_in_:
            print(f"âš ï¸ Shape mismatch: {os.path.basename(path)} â†’ {arr.shape[1]} vs {pca.n_features_in_}")
            continue

        # 5) PCA â†’ prediÃ§Ã£o
        X_pca = pca.transform(arr)
        y_pred = model.predict(X_pca).flatten()[0]

        # 6) Extrair valor real do nome do arquivo
        valor_real = float(os.path.basename(path).split("_")[-1].replace(".csv", ""))
        resultados.append((os.path.basename(path), valor_real, y_pred))

    except Exception as e:
        print(f"âš ï¸ Erro em {os.path.basename(path)}: {e}")

# â€”â€”â€” Salvar resultados brutos â€”â€”â€”
df_res = pd.DataFrame(resultados, columns=["amostra", "valor_real", "valor_predito"])
df_res.to_csv(os.path.join(pasta_resultados, "resultados.csv"), index=False)

# â€”â€”â€” CorreÃ§Ã£o polinomial grau 2 â€”â€”â€”
coef2, coef1, coef0 = np.polyfit(df_res["valor_predito"], df_res["valor_real"], deg=2)
df_res["valor_predito_corrigido"] = (
    coef2 * df_res["valor_predito"]**2 +
    coef1 * df_res["valor_predito"] +
    coef0
)
df_res.to_csv(os.path.join(pasta_resultados, "resultados_corrigidos.csv"), index=False)

print(f"\nâœ… Coeficientes de correÃ§Ã£o polinomial grau 2:")
print(f"   â†’ a2 (quadrÃ¡tico): {coef2:.8f}")
print(f"   â†’ a1 (linear):     {coef1:.8f}")
print(f"   â†’ a0 (constante):  {coef0:.8f}")

# â€”â€”â€” MÃ©tricas finais â€”â€”â€”
mae  = np.mean(np.abs(df_res["valor_real"] - df_res["valor_predito_corrigido"]))
rmse = np.sqrt(np.mean((df_res["valor_real"] - df_res["valor_predito_corrigido"])**2))
ss_res = np.sum((df_res["valor_real"] - df_res["valor_predito_corrigido"])**2)
ss_tot = np.sum((df_res["valor_real"] - np.mean(df_res["valor_real"]))**2)
r2    = 1 - (ss_res / ss_tot)

with open(os.path.join(pasta_resultados, "metrics_test.txt"), "w") as f:
    f.write(f"MAE: {mae:.4f}\n")
    f.write(f"RMSE: {rmse:.4f}\n")
    f.write(f"RÂ²: {r2:.4f}\n")

print(f"\nâœ… Resultados salvos em:\n"
      f"   â†’ {pasta_resultados}/resultados.csv\n"
      f"   â†’ {pasta_resultados}/resultados_corrigidos.csv ({len(df_res)} amostras)\n")
print("\nğŸ¯ Final TEST metrics (after polynomial correction):")
print(f"MAE: {mae:.2f} | RMSE: {rmse:.2f} | RÂ²: {r2:.4f}")
